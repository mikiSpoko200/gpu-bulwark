\chapter{OpenGL}

\section{Introduction}

OpenGL is an specification of an API for hardware accelerated computer graphics owned and maintained by the Khronos Group Inc.

Since it's inception  and up until 2016 with release of Vulkan it has been the only widely supported cross platform graphics API.


% From specification
TODO: opis opengl'a

\section{OpenGL objects}

OpenGL exposes an abstraction over GPU's resources called objects. In order to use given object it first must be bound to a var point in current OpenGL context. 

Objects contain internal state which can be queried using introspection. Objects are identified by a \textit{name} which is an unsigned 32 bit integer. There exists common object model which describes how most types of objects are managed.

\noindent Most types of object can be created with either call to\\

\centerline{
    \texttt{void} \textbf{Gen*s}(\texttt{sizei} \textit{n}, \texttt{uint} *\textit{objects})
}
\noindent which will allocate object's \textit{name} and subsequent call to \\

\centerline{
    \texttt{void} \textbf{Bind*}(\texttt{uint} \textit{name}, ...)
}
\noindent which will bind given object to the context and, if given object has never been bound before, allocate their internal state. Alternatively one can use\\

\centerline {
    \texttt{void} \textbf{Create*s}(\texttt{sizei} \textit{n}, \texttt{uint} *\textit{objects})
}
\noindent which will allocate both object's \textit{name} and its state but it will not set any context bindings. There exist separate namespace for each object type.

The most notable outliers that do not conform to the rules above are program objects, shader objects 

Objects can be deleted with \texttt{void} \textbf{Delete*s}(\texttt{sizei} \textit{n}, \texttt{uint} *\textit{objects}), bound with aforementioned \texttt{void} \textbf{Bind*}(\texttt{uint} \textit{name}, ...) which usually accepts additional parameter that specifies var point.

OpenGL specification defines set of publicly available object parameters which can be queries using introspection with \textbf{GetInteger*} family of functions. One notable usage is determining compilation and linking status for shaders and programs. 

\subsection{Buffer object}

Buffer objects provide means to allocate data stores in GPU memory. They can contain data of different format and purpose depending on buffer's target. Primary usage for buffers is to provide geometric information which includes vertex attribute values and indices for indexed rendering.

\subsection{Vertex Array object}

Modern OpenGL is generic over vertex format and only poses limitation on the number of such 
attributes and limits their values to glsl's scalar or vector types. 
Each attribute is assigned a zero-based index. Vertex Array object (VAO) assigns each active 
attribute information on how and where from to source vertex data, as well as, what is the
data type of provided attribute in glsl.

This can be seen as two separate pieces of information:
- in memory layout and access frequency
- interpretation / conversion of the data.

Originally all of that information was specified at one with\\

\centerline {
    void VertexAttrib*Pointer(

    )
}
\section{History}

IRIS GL, a proprietary graphics API, which later became OpenGL was initially developed by Silicon Graphics (SGI) during 1980's. SGI open sourced subset of their API as OpenGL due to mounting market pressure from SGI competitors (Sun Microsystems, Hewlett-Packard, IBM) who started providing their own APIs for hardware accelerated 3D graphics based on an existing open standard called PHIGS.

In 1992 OpenGL Architectural Review Board (OpenGL ARB) was established and it was tasked with development and maintenance of the OpenGL specification. This task was passed on to Khronos Group in 2006 where it remained ever since.

\section{Modern OpenGL}

\section{Graphics pipeline}

OpenGL 4.6 models graphics pipeline as follows:

\section*{OpenGL 4.6 Pipeline Description}

The OpenGL 4.6 pipeline is a sequence of stages that process and render 3D graphics onto the screen. It involves both fixed-function stages and programmable shader stages. Below is a detailed breakdown of each stage:

\subsection{Vertex Specification}

Before any rendering can being geometric information needs to provided as generic vertex attributes.

Vertex is an abstract composition of attributes that means to represent a point in 3D space of some object that is being modelled.
Generic stands from the fact that data associated with vertices has no intrinsic meaning.
Semantics of data are dictated by client provided vertex shader.

OpenGL sources data for each vertex attribute form a buffer. Each attribute is assigned an index.
Association between attribute with given index and a buffer from which should that attribute source its data is established by Vertex Array Object (abbriev. VAO).

Once all vertex attributes have their data sources assigned and properly configured, vertex specification can be considered finished and one could precede with further pipeline configuration.
In this instance vertices would be interpreted sequentially as appropriate primitives. This forces vertex data to be specified redundantly for lines and especially raw triangles since each triangle shares each edge with each neighboring triangle.

To better conserve memory one can use indexed rendering. This requires additional buffer filled with indices into main vertex buffer instead of inlined vertex data.
In case of basic triangle rendering (without using compressed representations like triangle fan or triangle / line strip) will still cause repetition but now only few byte wide indices instead of whole attributes which are substantially larger.

\subsection{Vertex Shader}

Vertex shader is the first programmable stage of OpenGL Pipeline and is one of two required shaders to execute a draw call, the other being the fragment shader.

Most commonly vertex shader performs 3 translations. From initial model space, world space, view space to final clip space which we will now discuss briefly.

\textbf{model space} - when a 3D model is created in 3D modelling software its vertex positions are specified to some local coordinate system (commonly center of an object).
These positions would commonly be loaded into gpu memory. Such objects can be easily placed in broader scene by providing a so called world transform performs transformation from model's local coordinate system
to scene's coordinate system.

\textbf{world space} - world space refers to coordinate system of a scene that uses multiple models by translating, scaling or rotating them.

\textbf{view space} - its common for 3D rendering applications to provide means of interacting with the scene. Wether its a 3D computer game, CAD program or medical data visualization we would like to be able to 
control how scene is displayed by moving a virtual camera. This can be expressed as yet another transformation of the coordinate system - we would like to transform coordinate system to align with the position of our camera.
This transformation is commonly called view transform.

\textbf{clip space} - having accounted for model position in a scene and user interactivity all that remains is to provide vertex data in form that subsequent fixed function pipeline stage - the rasterizer - expects.
Namely once vertex shader is finished fixed function processing will perform so called perspective divide and then clip all geometry to normalized device coordinates (NDC).
Output of vertex shader is a 4 component vector which corresponds to a 3D position in homogenious coordinate system used in computer graphics due to its ability to represent non linear transformations using matrices.
The output position of vertex is divided by the forth component in order to introduce perspective 

% TODO: Correct section about perspective - remark that perspective divide itself does not handle near and far clipping plane.

The main responsibility of vertex shader is to transform vertices to clip space, which will be discussed in future subsection. %TODO: Add link clip space% 

\subsection{Tessellation}

Tesselation stages were added as graphics hardware compute capability grew. With raw compute throughput outperforming bus throughput GPUs were equipped with hardware
tesselation unit which can subdivide a larger triangle into batch of smaller ones. This allows for efficient generation of geometric detail on chip alleviating the 
issue of limited PCI throughput.
To drive the tesselation stage two new shaders were introduced:
\begin{itemize}
    \item \textbf{Tesselation control shader} which configures how hardware tesselator should subdivide a triangle.
    \item \textbf{Tesselation evaluation shader} which performs transformations on vertices generated by the tesselator.
\end{itemize}

\subsection{Geometry shading}

Geometry shader was introduced prior to tesselation stage. They operate on assembled geometric primitives and may even access primitives neighbors.
Given primitive input geometry shaders output one or more primitive of the same type.

\subsection{Fixed function vertex post-processing}

Once all programmable vertex progressing has concluded, a series of fixed-function operations are applied to the vertices of the resulting primitives before rasterization.
These operations include transform feedback, which captures processed vertex data, 
primitive queries to gather information about the primitives being processed 
and flat shading which applies a uniform attribute value to a whole primitive.

Primitives then get clipped against clip volume and client-defined half-spaces.
The clip coordinates undergo perspective division, followed by viewport mapping to adjust for screen coordinates and depth range scaling.

\subsection{Rasterization}

If neither tesselation stage nor geometry stage was used in vertex processing, primitive assembly takes place (presence of any of the aforementioned stages would necessitate early primitive assembly). 
OpenGL converts geometric primitives used in currently processed draw call into base primitives which are points, lines and triangles.
Mathematical representation of primitives is used during rasterization to determine if given fragment falls inside of primitive being rasterized.

Process of rasterization requires determining if given pixel position falls inside of rendered primitive. This process needs to account for point and line thickness.
Polygon rasterization is obviously the most complex of the three. Prior to insidness test face culling is performed. 
This optimization culls a polygon based on the sign of surface normal computed based on edge ordering as specified in vertex array.
This helps reduce overdraw which can be one of two main bottlenecks in modern rendering system, the latter being insufficient memory bandwidth.

Once pixel location was deemed inside a primitive a fragment is generated. 
A Fragment is a collection of data corresponding to specific pixel location.
Most commonly its perspective corrected barycentric interpolation of vertex data across the primitive's surface.
Tough interpolation can be disabled from within vertex shader using \texttt{flat} qualifier on output variable declaration,
as well as perspective correction with \texttt{noperspective} qualifier.

Once fragments are computed early per-fragment tests take place.

\begin{itemize}
    \item \textbf{Ownership test} - determines if pixel at location (x, y) falls into the portion of the screen that active OpenGL context owns.
    \item \textbf{Scissor test} - checks if pixel at location (x, y) is contained within client provided list of axis aligned rectangles
    \item \textbf{Early Fragment tests} - stencil test, depth test and occlusion query which are normally performed after fragment processing can optionally be performed early. We discuss them in subsection on fragment post processing.
\end{itemize}

If all tests passed fragment is submitted for programable fragment processing.

\subsection{Fragment processing}

Programable fragment processing is performed by client provided fragment shader. The most essential task that fragment shader should perform is assign pixel a color.
For that purpose data interpolated from rasterization is used. 
Most commonly fragment shaders perform texture mapping, lighting calculations, parallax mapping to emulate geometric detail and screen space effects like ambient occlusion, 
use signed distance functions and implicit surface equations to render otherwise complex scenes all by itself or create volumetric effects like clouds or visualize CT scan results.

\subsection{Fragment post processing}

%TODO: Opisać depth test, stencil test i occlusion queries, alpha blending

\section{GLSL}

GLSL is a high level shading language with c like syntax developed by OpenGL Architecture Review Board to power programable processing stages in OpenGL pipeline. 
GLSL code is still relevant as it can be compiled into SPIR-V and used with Vulkan API.

\subsection*{Shaders}

Independent compilation units written in this language are called shaders. A program is a set of
shaders that are compiled and linked together, completely creating one or more of the
programmable stages of the API pipeline %TODO: quote from spec.

In OpenGL 4.6 and GLSL 4.60 there exist 6 types of shaders: vertex, tesselation control and evaluation, geometry, fragment and compute.
All shaders except compute shader control appropriate parts of OpenGL pipeline as described in subsections above. 

Compute shaders operate completely outside of graphics pipeline. They can access same resources as fragment or vertex shader like textures, buffers, images and atomic counters
but they are not expected to produce data with predetermined form or semantics. They offer general purpose compute capability on the GPU. 
They function similarly to other existing general purpose GPU compute APIs like CUDA or OpenCL.

\subsection{Variables}

Shaders 

\subsection{Variable type qualifiers}

% TODO: Describe that opengl uses different types and expands them into larger formats during execution

\subsection{Variable storage qualifiers}

% TODO: how qualifiers fall into pipeline model in code and how they are matched (hlists)

\subsection{Variable layout qualifiers}

% TODO: Layout matching between VAO and VS, between pipeline stages and how Program builder in out library matches uniform definitions with declarations based on them.
